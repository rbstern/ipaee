---
title: "Aula 6 - Distribui√ß√µes Normal, chi-quadrado e F"
author: "Rafael Bassi Stern"
date: 2018-04-04
bibliography: ipaee.bib
output: html_document
---

# Propriedades de vari√°veis aleat√≥rias

Uma forma de descrever a incerteza em rela√ß√£o
a uma vari√°vel aleat√≥ria √© por meio de sua 
**fun√ß√£o de densidade**.
Se $X$ √© uma vari√°vel aleat√≥ria, geralmente
designamos a fun√ß√£o de densidade de $X$ 
por $f_{X}(x)$.
O valor de $f_{X}(x)$ indica o qu√£o plaus√≠vel √©
que a vari√°vel aleat√≥ria $X$ assuma o valor $x$.
Por exemplo, a figura abaixo indica uma
vari√°vel aleat√≥ria cont√≠nua tal que 
todos os valores entre 0 e 1 s√£o igualmente plaus√≠veis.
Por isso, √© comum dizer que esta vari√°vel aleat√≥ria
tem densidade uniforme entre 0 e 1.

```{r message = FALSE, warning = FALSE}
library(tidyverse)
ggplot(data.frame(x = c(0, 1)), aes(x)) + 
stat_function(fun = dunif, colour = "red", n = 100)
```

Uma propriedade importante de uma fun√ß√£o de densidade √© que
podemos obter a probabilidade de que $X$ esteja entre dois valores,
$x_1$ e $x_2$, calculando a √°rea debaixo da densidade.
Note que de corre desta propriedade que 
a √°rea total debaixo da densidade √© $1$.
Por exemplo, a figura abaixo ilustra como
obter $P(0.25 < X < 0.5)$ quando 
$X$ tem densidade uniforme entre $0$ e $1$.
Note que, neste caso, a figura abaixo da curva √© 
um ret√¢ngulo de base $0.25$ e altura $1$ e, portanto,
de √°rea $0.25$. Assim, obtemos que 
$P(0.25 < X < 0.5) = 0.25$.
Tamb√©m, a √°rea total debaixo da densidade √©
dada por um quadrado de lado $1$, isto √©, $1$.
Portanto, como esper√°vamos, $P(0 < X < 1) = 1$.

```{r message = FALSE, warning = FALSE}
ggplot(data.frame(x = c(0, 1)), aes(x)) + 
stat_function(fun = dunif, colour = "red", n = 100) +
stat_function(fun = dunif, xlim = c(0.25, 0.5), geom = "area", alpha = 0.5) 
```

De forma geral, a √°rea debaixo de uma curva √©
dada por uma integral.
Neste curso n√£o usaremos esta rela√ß√£o,
mas √© √∫til saber que, 
se $X$ √© uma vari√°vel cont√≠nua, ent√£o
obtemos que
$$P(x_1 \leq X \leq x_2) = \int_{x_1}^{x_2} f_{X}(x)dx$$

Tamb√©m note que a √°rea entre $x_1$ e $x_2$
pode ser descrita como a √°rea √† esquerda de
$x_2$ subtra√≠da da √°rea √† esquerda de $x_1$.
Assim, se $X$ √© uma vari√°vel cont√≠nua,
tamb√©m vale a seguinte rela√ß√£o
$$P(x_1 \leq X \leq x_2) = P(X \leq x_2) - P(X \leq x_1)$$


A fun√ß√£o de densidade descreve toda
a incerteza sobre uma vari√°vel aleat√≥ria.
Contudo, pode ser dif√≠cil descrever e
analisar uma fun√ß√£o. Assim,
√© comum que certos aspectos de
uma vari√°vel aleat√≥ria sejam resumidos 
em n√∫meros. A seguir, estudamos
algumas destas medidas resumo.

- **Esperan√ßa** (m√©dia populacional): 
A esperan√ßa de uma var√≠avel aleat√≥ria, $X$ √©
denotada por $E[X]$ e descreve
uma medida de centralidade desta.
Se imaginarmos que, para cada poss√≠vel valor, $x$,
existe um peso de $f_{X}(x)$ na posi√ß√£o $x$, ent√£o 
$E[X]$ descreve o centro de massa desse sistema.
Tamb√©m, a m√©dia amostral e a esperan√ßa resumem 
a mesma caracter√≠stica.
Enquanto que a primeira descreve a centralidade para
uma vari√°vel em um banco de dados, 
uma vari√°vel aleat√≥ria j√° observada,
a segunda descreve a centralidade para uma vari√°vel aleat√≥ria,
isto √©, descreve a incerteza sobre 
uma observa√ß√£o antes que esta ocorra.
De forma t√©cnica, a esperan√ßa de 
uma vari√°vel aleat√≥ria cont√≠nua √© 
calculada da seguinte forma:
$$E[X] = \int_{-\infty}^{\infty}{x f_{X}(x)dx}$$

- **Vari√¢ncia** (populacional): 
A vari√¢ncia de uma vari√°vel aleat√≥ria, $X$, √©
denotada por $V[X]$ e indica um resumo da
variabilidade desta.
Assim como a vari√¢ncia amostral descreve 
a variabilidade de uma vari√°vel em um banco de dados (j√° observado),
a vari√¢ncia populacional descreve
a variabilidade de uma vari√°vel aleat√≥ria (ainda n√£o observada).
De forma t√©cnica, a vari√¢ncia de 
uma vari√°vel aleat√≥ria cont√≠nua √© 
calculada da seguinte forma:
$$V[X] = \int_{-\infty}^{\infty}{(x-E[X])^2 f_{X}(x)}dx$$
Semelhantemente ao caso da vari√¢ncia amostral,
a vari√¢ncia populacional n√£o √© medida na 
mesma escala da vari√°vel aleat√≥ria que ela representa.
Para obter esta escala, √© comum tomar a
raiz quadrada da vari√¢ncia populacional.
Esta medida √© chamada de **desvio padr√£o** (populacional).
Tamb√©m √© comum designarmos a vari√¢ncia de $X$ por
$\sigma^2_X$. Esta nota√ß√£o √© conveniente pois permite
designarmos o desvio padr√£o de $X$ por $\sigma_X$.

A seguir, estudaremos 
algumas fun√ß√µes de densidade
essenciais para este curso.

# Distribui√ß√£o normal

Uma das distribui√ß√µes mais usadas √© a Normal.
Formalmente, dizemos que $X$ tem 
distribui√ß√£o normal com 
m√©dia $\mu$ e vari√¢ncia $\sigma^2$ se
$X$ pode assumir qualquer n√∫mero real e
sua densidade, $f_{X}(x)$, tem a forma 
$$
 f_{X}(x) = 
 \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
$$
Como diremos muitas vezes neste curso que 
"$X$ tem distribui√ß√£o Normal com m√©dia $\mu$ e vari√¢ncia $\sigma^2$",
abreviaremos esta express√£o por $X \sim N(\mu,\sigma^2)$.
Se $X \sim N(\mu,\sigma^2)$, ent√£o obtem-se que
$E[X] = \mu$ e $Var[X] = \sigma^2$.
A figura abaixo exibe a densidade da $N(0,1)$, 
tamb√©m conhecida por "normal padr√£o".
```{r message = FALSE, warning = FALSE}
ggplot(data.frame(x = c(-3, 3)), aes(x)) + 
stat_function(fun = dnorm, colour="red", n = 100) 
```

Note que a densidade tem um formato de sino com
simetria ao redor do $0$.
Decorre que a normal padr√£o tem m√©dia $0$.
A densidade de uma normal com m√©dia $\mu$ e
vari√¢ncia $1$ ter√° o mesmo formato,
s√≥ que transladado por $\mu$.
Este fato √© ilustrado na figura a seguir,
em que as curvas azul e verdem indicam,
respectivamente, as densidades 
da $N(-1,1)$ e da $N(1,1)$.
```{r message = FALSE, warning = FALSE}
ggplot(data.frame(x = c(-4,4)), aes(x)) + 
stat_function(fun = dnorm, colour = "red", n = 100) +
stat_function(fun = function(x) dnorm(x, mean = -1), 
              colour = "blue", n = 100) +
stat_function(fun = function(x) dnorm(x, mean = 1), 
              colour = "green", n = 100) +
ylab("densidade")
```

Semelhantemente, a figura abaixo apresenta
nas curvas verde, vermelha e azul, respectivamente,
as distribui√ß√µes $N(0, 0.25)$, $N(0, 1)$ e $N(0, 4)$.
Note que a vari√¢ncia, $\sigma^2$, 
altera a escala da densidade da normal.
Quanto menor o valor de $\sigma^2$, 
mais a densidade est√° concentrada ao redor da m√©dia.

```{r message = FALSE, warning = FALSE}
ggplot(data.frame(x = c(-6,6)), aes(x)) + 
stat_function(fun = dnorm, colour = "red", n = 100) +
stat_function(fun = function(x) dnorm(x, sd = 2), 
              colour = "blue", n = 100) +
stat_function(fun = function(x) dnorm(x, sd = 0.5), 
              colour = "green", n = 100) +
ylab("densidade")
```

Uma rela√ß√£o √∫til √© que aproximadamente 95\% da 
densidade de uma $N(\mu,\sigma^2)$ est√°
concentrada entre $\mu-2\sigma$ e $\mu+2\sigma$.
Na figura acima, temos que $\mu=0$.
Assim, aproximadamente 95\% da √°rea das curvas 
verde, vermelha e azul est√° concentrada, 
respectivamente, em $[-1,1]$, $[-2,2]$ e $[-4,4]$.
De forma mais formal, 
se $X \sim N(\mu,\sigma^2)$ e 
$\approx$ significa aproximadamente, ent√£o
$$
P(\mu-2\sigma \leq X \leq \mu+2\sigma) 
\approx 0.95
$$

Se $X \sim N(\mu,\sigma^2)$, 
n√£o √© poss√≠vel descrever $P(X \leq x)$
de forma anal√≠tica. Contudo,
√© poss√≠vel obter uma aproxima√ß√£o anal√≠tica
para esta quantidade no **R** usando a fun√ß√£o *pnorm*. 
Por exemplo, o c√≥digo abaixo calcula
$P(X \leq 4)$ para uma $N(2,9)$.

```{r message = FALSE, warning = FALSE}
pnorm(4, mean = 2, sd = 3)
```

Tamb√©m a probabilidade de que 
uma $N(2,9)$ esteja entre $1$ e $4$
√© obtida da seguinte forma:

```{r message = FALSE, warning = FALSE}
pnorm(4, mean = 2, sd = 3) - pnorm(1, mean = 2, sd = 3)
```

√â poss√≠vel transformar qualquer distribui√ß√£o normal
em uma normal padr√£o por meio de transforma√ß√µes lineares.
Especificamente, se $X \sim N(\mu,\sigma^2)$, ent√£o
$\frac{X-\mu}{\sigma} \sim N(0,1)$. Por isso,
podemos imaginar que obtemos uma $N(\mu,\sigma^2)$,
ao multiplicar uma normal padr√£o por $\sigma$ e
somar $\mu$ ao resultado.
O processo de calcular $\frac{X-\mu}{\sigma}$ √©
frequentemente chamado de padroniza√ß√£o.

## Teorema Central do Limite

O Teorema Central do Limite √©
um dos resultados mais importantes em Estat√≠stica e
tamb√©m uma das raz√µes pelas quais 
a distribui√ß√£o √© t√£o importante neste curso.
De forma suscinta, ele dita que, se
$X_1, \ldots, X_n$ s√£o 
vari√°veis aleat√≥rias independentes que
tem a mesma distribui√ß√£o e tais que
$E[X_i] = \mu$ e $V[X_i] = \sigma^2$, ent√£o
a m√©dia amostral √© aproximadamente normal.
Mais especificamente,
$$\bar{X} \approx N\left(\mu,\frac{\sigma^2}{n}\right)$$
Note que esta aproxima√ß√£o vale
n√£o importa qual seja
a distribui√ß√£o de cada observa√ß√£o.
Assim, com pouqu√≠ssimas suposi√ß√µes √©
poss√≠vel aproximar a distribui√ß√£o 
da m√©dia amostral pela normal.
Se padronizarmos a m√©dia amostral,
obtemos a vers√£o mais usual do
Teorema do Limite Central:
$$\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \approx N(0,1)$$
A figura a seguir √© um histograma de
observa√ß√µes obtidas tomando a m√©dia de 
$100$ vari√°veis aleat√≥rias uniformes entre $0$ e $1$.
Note que cada uniforme tem m√©dia $0.5$ e as
m√©dias amostrais est√£o dispersas em torno deste valor.
Tamb√©m, a distribui√ß√£o uniforme entre $0$ e $1$ tem
vari√¢ncia $\frac{1}{12}$. Assim,
o Teorema Central do Limite dita que a
m√©dia de 100 destas distribui√ß√µes uniformes tem
desvio padr√£o $\sqrt{\frac{1}{12 \cdot 100}}$.
Isto √©, neste caso $\bar{X} \approx N(0.5, 0.03)$.
De fato, observamos na figura que
a maior parte das observa√ß√µes est√£o dispersas
a menos de dois desvios padr√µes, $0.06$,
da m√©dia populacional, $0.5$.

```{r message = FALSE, warning = FALSE}
medias = rep(NA, 1000)
for(ii in 1:1000) 
{
  medias[ii] = mean(runif(100, 0, 1))
}
ggplot(aes(x = medias), data = data.frame(medias)) +
geom_histogram(aes(y = ..density..)) +
geom_density(colour="red")
```

# Distribui√ß√£o chi-quadrado

- Se $X$ tem distribui√ß√£o chi-quadrado
  com $n$ graus de liberdade, escrevemos
  $X \sim \chi^2_n$. Neste caso,
  $$f_{X}(x) = \frac{x^{0.5n-1}\exp(-0.5x)}{2^{0.5n}\Gamma(0.5n)},$$
  $E[X]=n$ e $V[X]=2n$.

- Se $X \sim N(0,1)$, ent√£o 
  $X^2 \sim \chi^2_1$.
  
- Se $X_1, \ldots, X_n$ s√£o vari√°veis independentes e
  cada qual tem distribui√ß√£o $\chi^2_1$, ent√£o
  $\sum_{i=1}^n X_i \sim \chi^2_n$.
  
- No **R**, podemos obter
  a densidade e $P(X \leq x)$ para
  a chi-quadrado por meio dos comandos
  *dchisq* e *pchisq*.

# DistribuiÁ„o T de Student

- Designamos a distribuiÁ„o $T$ de Student com
$n$ graus de liberdade por $T_{n}$.

- Se $Z \sim N(0,1)$ e $S^2 \sim \chi^2_n$ s„o
  vari·veis independentes, ent„o
  $\frac{Z}{\sqrt{\frac{S^2}{n}}} \sim T_{n}$.

- No **R**, podemos obter
  a densidade e $P(X \leq x)$ para
  a T de Student por meio dos comandos
  *dt* e *pt*.

# Distribui√ß√£o F de Snedcor

- Se $X$ tem distribui√ß√£o $F$ com par√¢metros
  $d_1$ e $d_2$, ent√£o escrevemos
  $X \sim F_{d_1,d_2}$.
  
- $X_1 \sim \chi^2_{d_1}$, $X_2 \sim \chi^2_{d_2}$ e
  $X_1$ e $X_2$ s√£o independentes, ent√£o

$$
\frac{\frac{X_1}{d_1}}{\frac{X_2}{d_2}}
\sim F_{d_1,d_2}
$$

- No **R**, podemos obter
  a densidade e $P(X \leq x)$ para
  a distribui√ß√£o F por meio dos comandos
  *df* e *pf*.

# Exerc√≠cios

1. Se $X$ tem densidade entre uniforme entre $0$ e $1$ e
$0 \leq x_1, x_2 \leq 1$, calcule $P(x_1 \leq X \leq x_2)$.

2. Se $X$ tem densidade uniforme entre $1$ e $3$,
qual √© o valor da densidade de $X$ neste intervalo?

3. Calcule a esperan√ßa e a vari√¢ncia de uma vari√°vel aleat√≥ria
com distribui√ß√£o uniforme entre $0$ e $1$.

4. Ache um intervalo tal que uma $N(4,9)$ e
steja dentro deste com probabilidade aproximadamente $95\%$.

5. Se $X \sim N(4,9)$, utilize o **R** para
calcular $P(-1 \leq X  \leq 1)$.

6. Se $X \sim N(10, 100)$, indique 
uma transforma√ß√£o linear de $X$ que tem
distribui√ß√£o normal padr√£o.

7. Se $X_1, \ldots, X_n$ s√£o vari√°veis independentes
de mesma distribui√ß√£o e tais que 
$E[X_i] = 9$ e $V[X_i] = 16$, indique valores para
$a$ e $b$ tal que 
$P(a \leq \bar{X} \leq b) \approx 95\%$.

8. Um pesquisador utilizou uma mesma medida resumo
em diversas vari√°veis de seu banco de dados.
Para visualizar estas medidas, construiu 
um histograma delas.
Este histograma se encontra abaixo.
Com base no histograma, argumente se
a medida resumo poderia ou n√£o ser a m√©dia amostral.

```{r echo = FALSE, message = FALSE, warning = FALSE}
hist(rbeta(1000, 0.5, 0.5), main = "", xlab = "", ylab = "")
```

# Refer√™ncias 
